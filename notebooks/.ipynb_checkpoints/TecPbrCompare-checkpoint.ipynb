{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import glob\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "%config InteractiveShell.ast_node_interactivity='all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pbr_at_time(df, extract_time, time_delta='30min', return_single=False):\n",
    "    \"\"\"\n",
    "    This function returns a time specific portion of the PBR DataFrame consisting\n",
    "    of the previous 16min (as default) of the input extract_time and the post 5min.\n",
    "    If return_single=True, a resampled mean of that portion is returned as single \n",
    "    row DF\n",
    "    \"\"\"\n",
    "    \n",
    "    # ensure that the arguments are in the proper format for manipulation\n",
    "    st = pd.to_datetime(extract_time)    \n",
    "    td = pd.to_timedelta(time_delta)\n",
    "    m6 = pd.to_timedelta('5min')\n",
    "    \n",
    "    # create mask from relevant dates\n",
    "    mask = (df.index > st-td) & (df.index <= st+m6)\n",
    "    \n",
    "    # extracted dates DF\n",
    "    ext =  df.loc[mask]\n",
    "    \n",
    "    if not return_single:\n",
    "        \n",
    "        return ext.dropna(how='any')\n",
    "    \n",
    "    else:\n",
    "        # down sample the extracted dates to 5min buckets and return the row\n",
    "        # that is closest in time with the requested 'extract_time' parameter\n",
    "        ext = ext.resample('15min', label='right').mean().dropna(how='any')\n",
    "        \n",
    "        # index of 'nearest' to requested time\n",
    "        idx = ext.index.get_loc(st, method='nearest')#get index date\n",
    "        \n",
    "        # Series needs to be transformed for posterity\n",
    "        single_row = pd.DataFrame(ext.iloc[idx]).T\n",
    "        \n",
    "        return single_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbr_path='/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed'\n",
    "locs = []\n",
    "for root, dirs, files in os.walk(pbr_path):\n",
    "    for name in files:\n",
    "        if 'daily' not in name:\n",
    "            locs.append(pjoin(root, name))\n",
    "\n",
    "locs =  [locs[2], locs[1], locs[0], locs[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_3_preprocesed.csv',\n",
       " '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_2_preprocesed.csv',\n",
       " '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_1_preprocesed.csv',\n",
       " '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_4_preprocesed.csv']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_1_preprocesed.csv',\n",
       " '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_2_preprocesed.csv',\n",
       " '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_3_preprocesed.csv',\n",
       " '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_4_preprocesed.csv']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_dates = ['2019-04-17 21:00:00', '2019-04-18 17:30:00',\n",
    "               '2019-04-19 12:30:00', '2019-04-20 16:45:00',\n",
    "               '2019-04-21 20:00:00', '2019-04-22 14:00:00',\n",
    "               '2019-04-23 15:30:00', '2019-04-24 17:30:00',\n",
    "               '2019-04-25 16:30:00', '2019-04-26 17:45:00',\n",
    "               '2019-04-27 18:15:00', '2019-04-28 18:45:00',\n",
    "               '2019-04-29 17:45:00']\n",
    "\n",
    "exp3_dates = ['2019-05-11 19:00:00', '2019-05-12 19:30:00',\n",
    "               '2019-05-13 19:45:00', '2019-05-14 20:30:00',\n",
    "               '2019-05-15 17:15:00', '2019-05-16 16:45:00',\n",
    "               '2019-05-17 14:30:00', '2019-05-20 15:15:00',\n",
    "               '2019-05-21 14:45:00', '2019-05-22 15:15:00',\n",
    "               '2019-05-23 15:00:00', '2019-05-24 16:45:00']\n",
    "\n",
    "\n",
    "# comparison 1\n",
    "# Extract the above dates from the the PBR respective exp # datasets using the date extraction tool\n",
    "# Apply Old & New model to PBR data and see how these compare against each other\n",
    "\n",
    "\n",
    "#comparison\n",
    "# Create a tool which extracts the datetime row from the raw CC data files\n",
    "# these dates will then be used to extract absorbance readings from their\n",
    "# respective pbr data, depending on how comparison1 fares we could then\n",
    "# say something about what we should have expected on exp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use too glob library to extract from each day's T1, the time at which it was\n",
    "# measured, this will give you a list of datetime which you can then extract from\n",
    "# the pbr preprocessed data.... \n",
    "\n",
    "# having done the comparison above: i.e. compara how the tecan measurements compare\n",
    "# against the pbr data\n",
    "path0 = '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/exp?/cell_counter/*d?_t1_01.#m4' # this works\n",
    "path1 = '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/exp?/cell_counter/*_d??_t1_01.#m4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global dataframe\n",
    "\n",
    "date_times = {'xp1':{},\n",
    "              'xp2':{},\n",
    "              'xp3':{},\n",
    "              'xp4':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [path0, path1]:\n",
    "    for path_str in glob.iglob(path):\n",
    "        path_str\n",
    "\n",
    "        splt = path_str.split(sep='_') \n",
    "        xpN = splt[-4]\n",
    "        xpD = splt[-3]\n",
    "\n",
    "        # load files\n",
    "        f = open(path_str)\n",
    "        lines = f.readlines()[31]\n",
    "\n",
    "        # the files are standardized thus in the 32nd line\n",
    "        # we selected the True values which encompass the\n",
    "        # time at which these measurements were made, this\n",
    "        # only works with numpy arrays, however\n",
    "        try:\n",
    "\n",
    "            selector = [False, False, False, True, False, True, True, True]\n",
    "            #lines.strip('\\n').split(' ')\n",
    "            asarray = np.array(lines.strip('\\n').split(' '))[selector]\n",
    "\n",
    "        except:\n",
    "            selector = [False, False, False, True, False, False, True, True, True]\n",
    "            #lines.strip('\\n').split(' ')\n",
    "            asarray = np.array(lines.strip('\\n').split(' '))[selector]\n",
    "\n",
    "        # join the datetime informatio and convert to pd.datetime obj\n",
    "        datetime = ' '.join([*asarray][::-1])\n",
    "        datetime = pd.to_datetime(datetime)\n",
    "\n",
    "        # append to dictionary\n",
    "        date_times[xpN][xpD] = datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dates also exist in the all cellcounts datasheet, compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you have done this ask pepe for other tecan-measured data if he has it for exp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>T1680</th>\n",
       "      <th>T1730</th>\n",
       "      <th>T1750</th>\n",
       "      <th>T2680</th>\n",
       "      <th>T2730</th>\n",
       "      <th>T2750</th>\n",
       "      <th>T3680</th>\n",
       "      <th>T3730</th>\n",
       "      <th>T3750</th>\n",
       "      <th>...</th>\n",
       "      <th>T7B_p680_730_560</th>\n",
       "      <th>T7C_p680_730_560</th>\n",
       "      <th>T7B_p680_750_560</th>\n",
       "      <th>T7C_p680_750_560</th>\n",
       "      <th>T8B_p680_720_560</th>\n",
       "      <th>T8C_p680_720_560</th>\n",
       "      <th>T8B_p680_730_560</th>\n",
       "      <th>T8C_p680_730_560</th>\n",
       "      <th>T8B_p680_750_560</th>\n",
       "      <th>T8C_p680_750_560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-17 20:55:00</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145820</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.144321</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.113544</td>\n",
       "      <td>0.018788</td>\n",
       "      <td>0.134066</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.133698</td>\n",
       "      <td>0.008530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-18 17:25:00</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.2022</td>\n",
       "      <td>0.1835</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143023</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.144264</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.116450</td>\n",
       "      <td>0.020665</td>\n",
       "      <td>0.137578</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>0.137586</td>\n",
       "      <td>0.009907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-19 12:25:00</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>0.1831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135463</td>\n",
       "      <td>0.024290</td>\n",
       "      <td>0.137453</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>0.102202</td>\n",
       "      <td>0.062330</td>\n",
       "      <td>0.123283</td>\n",
       "      <td>0.051601</td>\n",
       "      <td>0.123969</td>\n",
       "      <td>0.051252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-20 16:40:00</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1493</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142132</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.140445</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.101756</td>\n",
       "      <td>0.034428</td>\n",
       "      <td>0.121158</td>\n",
       "      <td>0.024553</td>\n",
       "      <td>0.122979</td>\n",
       "      <td>0.023626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-21 19:55:00</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>0.1476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143788</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145497</td>\n",
       "      <td>-0.000710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time   T1680   T1730   T1750   T2680   T2730   T2750  \\\n",
       "0  2019-04-17 20:55:00  0.1221  0.1040  0.1052  0.1240  0.1043  0.1055   \n",
       "1  2019-04-18 17:25:00  0.1917  0.1720  0.1720  0.2022  0.1835  0.1808   \n",
       "2  2019-04-19 12:25:00  0.1526  0.1310  0.1313  0.1594  0.1371  0.1374   \n",
       "3  2019-04-20 16:40:00  0.1320  0.1215  0.1225  0.1328  0.1199  0.1219   \n",
       "4  2019-04-21 19:55:00  0.1302     NaN  0.1211  0.1345     NaN  0.1208   \n",
       "\n",
       "    T3680   T3730   T3750  ...  T7B_p680_730_560  T7C_p680_730_560  \\\n",
       "0  0.1158  0.1012  0.1029  ...          0.145820          0.001201   \n",
       "1  0.2101  0.1837  0.1799  ...          0.143023          0.001220   \n",
       "2  0.2185  0.1853  0.1831  ...          0.135463          0.024290   \n",
       "3  0.1625  0.1493  0.1486  ...          0.142132          0.003871   \n",
       "4  0.1476     NaN  0.1383  ...               NaN               NaN   \n",
       "\n",
       "   T7B_p680_750_560  T7C_p680_750_560  T8B_p680_720_560  T8C_p680_720_560  \\\n",
       "0          0.144321          0.001964          0.113544          0.018788   \n",
       "1          0.144264          0.000589          0.116450          0.020665   \n",
       "2          0.137453          0.023277          0.102202          0.062330   \n",
       "3          0.140445          0.004730          0.101756          0.034428   \n",
       "4          0.143788         -0.001426               NaN               NaN   \n",
       "\n",
       "   T8B_p680_730_560  T8C_p680_730_560  T8B_p680_750_560  T8C_p680_750_560  \n",
       "0          0.134066          0.008342          0.133698          0.008530  \n",
       "1          0.137578          0.009911          0.137586          0.009907  \n",
       "2          0.123283          0.051601          0.123969          0.051252  \n",
       "3          0.121158          0.024553          0.122979          0.023626  \n",
       "4               NaN               NaN          0.145497         -0.000710  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_3_preprocesed.csv',\n",
       " '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_2_preprocesed.csv',\n",
       " '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_1_preprocesed.csv',\n",
       " '/home/rdmtinez/Desktop/MScThesis/data_o/pbr/pbr_exp_preprocessed/pbr_exp_4_preprocesed.csv']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load TecMeasd Modeled Data\n",
    "# for these exact experiemts x2 x3\n",
    "# pull the PBR abs measurements for these experiments dates\n",
    "# apply the model and compare them against each other,\n",
    "# how closely do they align... is it regressable, if regressable, there is a high degree\n",
    "# of correlation OR they match exactly  along the 1:1 LINE, this would mean the models\n",
    "# are 'perfect'\n",
    "# \n",
    "path = '/home/rdmtinez/Documents/B-IT MS Program/Masters Thesis/data_o/pbr/pbr_modeled_output_data'\n",
    "\n",
    "tcx2= pd.read_csv(pjoin(path,'tec_measd_exp2_modeled_output.csv'))\n",
    "tcx3= pd.read_csv(pjoin(path,'tec_measd_exp3_modeled_output.csv'))\n",
    "\n",
    "\n",
    "tcx2.head()\n",
    "\n",
    "\n",
    "\n",
    "# load PBR data\n",
    "\n",
    "\n",
    "pbr1 = pd.read_csv(locs[0])\n",
    "pbr2 = pd.read_csv(locs[1])\n",
    "pbr3 = pd.read_csv(locs[2])\n",
    "pbr4 = pd.read_csv(locs[3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# extract dates from pbr_cell counts data because its more complete than what you extracted\n",
    "# above for exp4, (above extracted dates should match).... you need to extract these dates\n",
    "# so that you can:\n",
    "    # 1. check the measurements given by PEPE with the averages extracted by your function\n",
    "            # they should be very close\n",
    "    # 2. apply the a680_a720 model to those dates rows\n",
    "    # 3. IF the first analysis of tecmesd data values\n",
    "    # match along the 1:1 line then its likely that these \n",
    "    # measurements in the tubes are fairly truthful (depending on the ratio analysis)\n",
    "    # if there is a HIGH Degree of Correlation (which is what I'm thinking) then\n",
    "    # do a regression and obtain kT, this kT is another coversion factor to the PBR\n",
    "    # data, if this is the case can we ignore the other constants\n",
    "    \n",
    "path = '/home/rdmtinez/Documents/B-IT MS Program/Masters Thesis/data_o/pbr'\n",
    "fname = 'all_pbr_cell_counter_results.csv'\n",
    "\n",
    "\n",
    "# apply model extracted dates data to pbr\n",
    "# compare\n",
    "\n",
    "# apply the new models to the old calibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
